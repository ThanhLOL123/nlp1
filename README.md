# Vietnamese NLP Pipeline

A comprehensive, modular pipeline for Vietnamese Natural Language Processing that provides state-of-the-art text processing capabilities with multiple backend support and extensive evaluation tools.

## ğŸš€ Features

### Core NLP Components
- **Advanced Tokenization**: Multiple algorithms (Underthesea, PyVi, Hybrid) for robust Vietnamese word segmentation
- **POS Tagging**: Part-of-speech tagging with standardized universal tags and multiple backend support
- **Tone Processing**: Complete Vietnamese tone analysis, removal, and restoration capabilities
- **Text Preprocessing**: Intelligent normalization for social media, email, URL, and general text cleaning

### Pipeline Architecture
- **Modular Design**: Easily swappable components for different use cases
- **Configuration-Driven**: YAML-based configuration for flexible pipeline customization  
- **Multiple Backends**: Support for Underthesea, PyVi, and Transformer-based models
- **Performance Monitoring**: Built-in timing and resource usage tracking

### Evaluation & Benchmarking
- **Comprehensive Metrics**: Accuracy, F1-score, precision, recall for all components
- **Dataset Support**: VLSP 2013, VLSP 2016, UIT Vietnamese Students' Feedback
- **Comparative Analysis**: Side-by-side performance comparison of different methods
- **Visualization**: Performance charts and confusion matrices

### Data Processing
- **Multiple Dataset Loaders**: Built-in support for major Vietnamese NLP datasets
- **Test Sample Generation**: Automatic creation of test cases across different text categories
- **Batch Processing**: Efficient processing of large text corpora

## ğŸ“¦ Installation

### Prerequisites
- Python 3.8+
- pip package manager

### Setup Instructions

1. **Clone the repository:**
   ```bash
   git clone https://github.com/your-username/vietnamese-nlp-pipeline.git
   cd vietnamese-nlp-pipeline
   ```

2. **Create and activate a virtual environment:**
   
   **Windows:**
   ```cmd
   python -m venv venv
   .\venv\Scripts\activate
   ```
   
   **macOS/Linux:**
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Download datasets (optional):**
   ```bash
   python scripts/download_data.py
   ```
   > Note: Some datasets like VLSP require manual download due to licensing requirements

## ğŸ¯ Quick Start

### Pipeline API Usage

```python
from src.pipeline import VietnameseNLPPipeline

# Initialize with configuration
pipeline = VietnameseNLPPipeline('configs/config.yaml')

# Process Vietnamese text
text = "ChÃ ng trai 9X Quáº£ng Trá»‹ khá»Ÿi nghiá»‡p tá»« náº¥m sÃ²"
result = pipeline.process(text, verbose=True)

# Access results
print("Original:", result.original_text)
print("Tokens:", result.tokens)
print("POS Tags:", result.pos_tags)
print("Tone Info:", result.tone_info)
print("Processing Time:", result.processing_time)
```

### Command Line Interface

**Demo Mode** - Test on sample sentences:
```bash
python main.py --mode demo
```

**Example Output:**
```
============================================================
Category: SIMPLE
============================================================

Input: TÃ´i Ä‘i há»c
Tokens: TÃ´i | Ä‘i | há»c
POS Tags: [('TÃ´i', 'P'), ('Ä‘i', 'V'), ('há»c', 'V')]

Input: HÃ´m nay trá»i Ä‘áº¹p
Tokens: HÃ´m nay | trá»i | Ä‘áº¹p
POS Tags: [('HÃ´m nay', 'N'), ('trá»i', 'N'), ('Ä‘áº¹p', 'A')]

============================================================
Category: COMPLEX
============================================================

Input: ChÃ ng trai 9X Quáº£ng Trá»‹ khá»Ÿi nghiá»‡p tá»« náº¥m sÃ²
Tokens: ChÃ ng | trai | 9X | Quáº£ng Trá»‹ | khá»Ÿi nghiá»‡p | tá»« | náº¥m | sÃ²
POS Tags: [('ChÃ ng', 'Nc'), ('trai', 'N'), ('9X', 'N'), ('Quáº£ng Trá»‹', 'Np'), ('khá»Ÿi nghiá»‡p', 'V'), ('tá»«', 'E'), ('náº¥m', 'N'), ('sÃ²', 'M')]

============================================================
Category: SOCIAL_MEDIA
============================================================

Input: e Æ¡i cho a há»i cÃ¡i nÃ y bao nhieu tien vay
Tokens: e | Æ¡i | cho | a | há»i | cÃ¡i | nÃ y | bao | nhieu | tien | vay
POS Tags: [('e', 'V'), ('Æ¡i', 'I'), ('cho', 'E'), ('a', 'N'), ('há»i', 'V'), ('cÃ¡i', 'Nc'), ('nÃ y', 'P'), ('bao', 'N'), ('nhieu', 'N'), ('tien', 'V'), ('vay', 'V')]

============================================================
Category: MISSING_TONES
============================================================

Input: toi muon hoc tieng viet
Tokens: toi | muon | hoc | tieng | viet
POS Tags: [('toi', 'N'), ('muon', 'V'), ('hoc', 'N'), ('tieng', 'N'), ('viet', 'M')]
Restored: TÃ´i muá»‘n há»c tiáº¿ng Viá»‡t

============================================================
Category: MIXED_LANGUAGE
============================================================

Input: TÃ´i Ä‘ang há»c Machine Learning
Tokens: TÃ´i | Ä‘ang | há»c | Machine | Learning
POS Tags: [('TÃ´i', 'P'), ('Ä‘ang', 'R'), ('há»c', 'V'), ('Machine', 'Np'), ('Learning', 'Np')]
```

**Evaluation Mode** - Evaluate on specific datasets:
```bash
python main.py --mode evaluate --dataset vlsp2013 --vlsp-path ./data/raw/vlsp2013
```

**Benchmark Mode** - Compare different methods:
```bash
python main.py --mode benchmark
```

### Jupyter Notebook

Explore the interactive demo:
```bash
jupyter notebook notebooks/01_pipeline_demo.ipynb
```

## âš™ï¸ Configuration

Configure the pipeline behavior through `configs/config.yaml`:

```yaml
pipeline:
  tokenizer:
    method: "hybrid"  # underthesea, pyvi, vncorenlp, hybrid
    
  pos_tagger:
    method: "underthesea"  # underthesea, pyvi, transformer
    
  tone_processor:
    remove_method: "pyvi"
    add_method: "pyvi"
    analyze_patterns: true

data:
  vlsp2013_path: "data/raw/vlsp2013"
  vlsp2016_path: "data/raw/vlsp2016"
  
evaluation:
  metrics: [accuracy, f1_score, precision, recall]
  save_confusion_matrix: true
```

## ğŸ§ª Component Usage

### Individual Components

**Tokenizer:**
```python
from src.tokenizer import VietnameseTokenizer

tokenizer = VietnameseTokenizer('hybrid')
tokens = tokenizer.tokenize("Viá»‡t Nam tÆ°Æ¡i Ä‘áº¹p")
```

**POS Tagger:**
```python
from src.pos_tagger import VietnamesePOSTagger

tagger = VietnamesePOSTagger('underthesea')
pos_tags = tagger.tag(['Viá»‡t', 'Nam', 'tÆ°Æ¡i', 'Ä‘áº¹p'])
```

**Tone Processor:**
```python
from src.tone_processor import ToneProcessor

processor = ToneProcessor()
tone_info = processor.analyze_text("Xin chÃ o")
no_tones = processor.remove_tones("Xin chÃ o")
```

## ğŸ“Š Supported Datasets

- **VLSP 2013**: Vietnamese word segmentation dataset
- **VLSP 2016**: Extended Vietnamese NLP tasks  
- **UIT Vietnamese Students' Feedback**: Sentiment analysis dataset (auto-downloaded)
- **Custom datasets**: Easy integration through the data loader API

## ğŸ§ª Testing

Run the test suite:
```bash
pytest
```

Run with coverage:
```bash
pytest --cov=src tests/
```

## ğŸ“ˆ Performance

The pipeline provides detailed performance metrics:
- **Processing Speed**: Component-level timing analysis
- **Memory Usage**: Resource consumption monitoring  
- **Accuracy Metrics**: F1-score, precision, recall for all tasks
- **Comparative Analysis**: Side-by-side method comparison

## âš ï¸ Current Limitations

### Technical Limitations
- **Language Support**: Currently focused only on Vietnamese language processing
- **Model Dependencies**: Relies on external libraries (Underthesea, PyVi) for core functionality
- **Memory Usage**: Large transformer models may require significant RAM (8GB+ recommended)
- **Processing Speed**: Sequential processing may be slow for large document collections

### Dataset Limitations
- **VLSP Datasets**: Require manual download due to licensing restrictions
- **Domain Specificity**: Best performance on formal Vietnamese text; informal/social media text may have reduced accuracy
- **Text Length**: Very long documents (>10k characters) may experience performance degradation

### Feature Limitations
- **Real-time Processing**: Not optimized for real-time streaming applications
- **GPU Acceleration**: Limited GPU support for transformer-based components
- **Custom Models**: No built-in training capabilities for domain-specific models
- **Language Detection**: No automatic Vietnamese text detection

## ğŸš€ Future Features

### Planned Enhancements

#### **Version 2.0 - Advanced Processing**
- **ğŸ”¥ Neural Models**: Integration of Vietnamese BERT, PhoBERT, and other transformer models
- **âš¡ GPU Acceleration**: CUDA support for faster processing with transformer models
- **ğŸŒŠ Streaming API**: Real-time text processing capabilities
- **ğŸ“± Mobile Support**: Lightweight models for mobile and edge deployment

#### **Version 2.2 - Advanced Features**
- **ğŸ§  Named Entity Recognition**: Person, location, organization identification
- **ğŸ’­ Sentiment Analysis**: Emotion and opinion detection
- **ğŸ“Š Text Classification**: Document categorization and topic modeling
- **ğŸ”— Dependency Parsing**: Syntactic relationship analysis

#### **Version 2.3 - Enterprise Features**
- **â˜ï¸ Cloud API**: RESTful API for cloud deployment
- **ğŸ“ˆ Analytics Dashboard**: Web-based performance monitoring
- **ğŸ”§ Auto-tuning**: Automatic hyperparameter optimization
- **ğŸ“¦ Docker Support**: Containerized deployment options

### Research & Development
- **ğŸ“š Custom Training**: Framework for training domain-specific models
- **ğŸ”¬ Active Learning**: Semi-supervised learning for data annotation
- **ğŸ¨ Data Augmentation**: Automatic Vietnamese text augmentation techniques
- **ğŸ” Explainable AI**: Model interpretability and explanation features

### Community Features
- **ğŸ‘¥ Model Hub**: Community-contributed models and datasets
- **ğŸ“– Documentation**: Interactive tutorials and API documentation
- **ğŸ“ Educational**: Vietnamese NLP learning resources and examples
- **ğŸ† Benchmarks**: Standardized evaluation on Vietnamese NLP tasks

## ğŸ“ Project Structure

```
vietnamese-nlp-pipeline/
â”œâ”€â”€ ğŸ“ configs/                    # Configuration files
â”‚   â””â”€â”€ config.yaml               # Main pipeline configuration
â”œâ”€â”€ ğŸ“ data/                      # Data storage
â”‚   â”œâ”€â”€ ğŸ“ raw/                   # Original datasets
â”‚   â”œâ”€â”€ ğŸ“ processed/             # Processed datasets  
â”‚   â””â”€â”€ ğŸ“ results/               # Evaluation results and visualizations
â”‚       â”œâ”€â”€ benchmark_results.csv
â”‚       â”œâ”€â”€ benchmark_comparison.png
â”‚       â””â”€â”€ evaluation_report.txt
â”œâ”€â”€ ğŸ“ notebooks/                 # Jupyter notebooks
â”‚   â””â”€â”€ 01_pipeline_demo.ipynb   # Interactive pipeline demonstration
â”œâ”€â”€ ğŸ“ scripts/                   # Utility scripts
â”‚   â””â”€â”€ download_data.py          # Dataset download helper
â”œâ”€â”€ ğŸ“ src/                       # Core source code
â”‚   â”œâ”€â”€ pipeline.py               # Main pipeline orchestrator
â”‚   â”œâ”€â”€ tokenizer.py              # Vietnamese tokenization
â”‚   â”œâ”€â”€ pos_tagger.py             # Part-of-speech tagging
â”‚   â”œâ”€â”€ tone_processor.py         # Vietnamese tone processing
â”‚   â”œâ”€â”€ preprocessor.py           # Text preprocessing utilities
â”‚   â”œâ”€â”€ evaluator.py              # Performance evaluation
â”‚   â””â”€â”€ data_loader.py            # Dataset loading utilities
â”œâ”€â”€ ğŸ“ tests/                     # Unit and integration tests
â”‚   â””â”€â”€ test_pipeline.py          # Pipeline test cases
â”œâ”€â”€ main.py                       # CLI entry point
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # Project documentation
```

## ğŸ› ï¸ Advanced Usage

### Custom Model Integration

```python
# Add custom tokenizer
from src.tokenizer import VietnameseTokenizer

class CustomTokenizer(VietnameseTokenizer):
    def custom_tokenize(self, text):
        # Your custom tokenization logic
        return tokens

# Use in pipeline
pipeline.tokenizer = CustomTokenizer('custom')
```

### Batch Processing

```python
texts = ["Text 1", "Text 2", "Text 3"]
results = []

for text in texts:
    result = pipeline.process(text)
    results.append(result)
    
# Analyze batch results
processing_times = [r.processing_time for r in results]
```

### Performance Analysis

```python
from src.evaluator import PipelineEvaluator

evaluator = PipelineEvaluator('data/results')

# Evaluate tokenization
predictions = [result.tokens for result in results]
ground_truth = [...]  # Your ground truth data

metrics = evaluator.evaluate_tokenization(predictions, ground_truth)
print(f"Tokenization F1: {metrics['f1']:.3f}")
```

## ğŸ”§ Dependencies

### Core Libraries
- **underthesea** (6.7.0): Vietnamese NLP toolkit
- **pyvi** (0.1.1): Vietnamese text processing  
- **transformers** (4.36.0): Transformer-based models
- **torch** (2.1.0): Deep learning framework

### Data & Analysis
- **pandas** (2.1.4): Data manipulation
- **numpy** (1.24.3): Numerical computing
- **scikit-learn** (1.3.2): Machine learning metrics
- **matplotlib** (3.8.2): Plotting and visualization
- **seaborn** (0.13.0): Statistical visualization

### Development
- **pytest** (7.4.3): Testing framework
- **jupyter** (1.0.0): Interactive notebooks
- **pyyaml** (6.0.1): Configuration management

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/new-feature`)
3. Commit your changes (`git commit -am 'Add new feature'`)
4. Push to the branch (`git push origin feature/new-feature`)
5. Create a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ”— References

- [Underthesea](https://github.com/undertheseanlp/underthesea): Vietnamese NLP Toolkit
- [PyVi](https://github.com/trungtv/pyvi): Vietnamese tokenizer
- [VLSP Shared Tasks](https://vlsp.org.vn/): Vietnamese Language and Speech Processing
- [UIT-ViSFD](https://huggingface.co/datasets/uitnlp/vietnamese_students_feedback): Vietnamese Students' Feedback Dataset

